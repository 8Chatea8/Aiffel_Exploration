{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deeb48d7",
   "metadata": {},
   "source": [
    "# 한국어 데이터로 챗봇 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2be82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995e6db",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기\n",
    "\n",
    "데이터셋 출처: https://github.com/songys/Chatbot_data/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792ec614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('~/aiffel/Exploration/Aiffel_Exploration/Ex05/data/ChatbotData .csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb19f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11823,), (11823,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = data['Q']\n",
    "answers = data['A']\n",
    "\n",
    "questions.shape, answers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae904b05",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3218b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # 단어와 구두점 사이 거리 만들기\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c129e49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 11823)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_questions = []\n",
    "pre_answers = []\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    sentence = questions[i]\n",
    "    pre_questions.append(preprocess_sentence(sentence))\n",
    "    \n",
    "    sentence = answers[i]\n",
    "    pre_answers.append(preprocess_sentence(sentence))\n",
    "    \n",
    "len(pre_questions), len(pre_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67090bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 500번째 질문 샘플: 나 버림 받은 거 같아\n",
      "전처리 후 500번째 답변 샘플: 아닐거예요 . \n"
     ]
    }
   ],
   "source": [
    "print(f'전처리 후 500번째 질문 샘플: {pre_questions[499]}')\n",
    "print(f'전처리 후 500번째 답변 샘플: {pre_answers[499]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ba9ee",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33188ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(pre_questions + pre_answers, \n",
    "                                                                      target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffb43fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' . ',\n",
       " ' ? ',\n",
       " '거예요',\n",
       " '수_',\n",
       " '게_',\n",
       " '너무_',\n",
       " '더_',\n",
       " '거_',\n",
       " '좋아하는_',\n",
       " '는_',\n",
       " '이_',\n",
       " '을_',\n",
       " '잘_',\n",
       " '도_',\n",
       " '고_',\n",
       " '요',\n",
       " '것_',\n",
       " '많이_',\n",
       " '안_',\n",
       " '좋은_',\n",
       " '같아요',\n",
       " '한_',\n",
       " '좀_',\n",
       " '있어요',\n",
       " '싶어',\n",
       " '가_',\n",
       " '나_',\n",
       " '에_',\n",
       " '있을_',\n",
       " '지_',\n",
       " '해보세요',\n",
       " '은_',\n",
       " '사람_',\n",
       " '할_',\n",
       " '해',\n",
       " '같아',\n",
       " '네',\n",
       " ' ! ',\n",
       " '면_',\n",
       " '건_',\n",
       " '사람이_',\n",
       " '를_',\n",
       " '마세요',\n",
       " '다_',\n",
       " '하고_',\n",
       " '지',\n",
       " '하는_',\n",
       " '보세요',\n",
       " '죠',\n",
       " '어']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.subwords[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10d0fac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8170"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20a3ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a40fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8170]\n",
      "END_TOKEN의 번호 : [8171]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29c77365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8172\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3e9c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = []\n",
    "output_length = []\n",
    "\n",
    "for (sentence1, sentence2) in zip(pre_questions, pre_answers):\n",
    "    sentence1 = tokenizer.encode(sentence1)\n",
    "    sentence2 = tokenizer.encode(sentence2)\n",
    "    \n",
    "    input_length.append(len(sentence1))\n",
    "    output_length.append(len(sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef321210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(input_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa9a41f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(output_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c82c318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "        \n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "    \n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs, \n",
    "                                                                     maxlen=MAX_LENGTH, \n",
    "                                                                     padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_outputs, \n",
    "                                                                      maxlen=MAX_LENGTH, \n",
    "                                                                      padding='post')\n",
    "    \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b41bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8172\n",
      "필터링 후의 질문 샘플 개수: 11791\n",
      "필터링 후의 답변 샘플 개수: 11791\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(pre_questions, pre_answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0943fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4642060",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bda4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3d65011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕드 어텐션\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40f9a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티 헤드 어텐션\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd7c6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 마스킹\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4dfb5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 룩 어헤드 마스킹\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b95d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 레이어\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a68e6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "                units=units,\n",
    "                d_model=d_model,\n",
    "                num_heads=num_heads,\n",
    "                dropout=dropout,\n",
    "                name=\"encoder_layer_{}\".format(i),\n",
    "            )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98c694d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 레이어\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "                          outputs=outputs,\n",
    "                          name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "816d3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "                units=units,\n",
    "                d_model=d_model,\n",
    "                num_heads=num_heads,\n",
    "                dropout=dropout,\n",
    "                name='decoder_layer_{}'.format(i),\n",
    "            )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "                           outputs=outputs,\n",
    "                           name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe582254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 함수\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "        )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "        )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f282f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3146240     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3673600     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8172)   2100204     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,920,044\n",
      "Trainable params: 8,920,044\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39b6c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90628d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "136002c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f97bba5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 14s 39ms/step - loss: 2.9520 - accuracy: 0.0658\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 2.3902 - accuracy: 0.1029\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 2.0395 - accuracy: 0.1054\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.8890 - accuracy: 0.1129\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.7713 - accuracy: 0.1194\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.6505 - accuracy: 0.1282\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.5160 - accuracy: 0.1404\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.3673 - accuracy: 0.1563\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.2069 - accuracy: 0.1734\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.0395 - accuracy: 0.1922\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "94b5682c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], label='loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], label='accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce308c1",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a104dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c81a1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode([i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c2fcbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 점심 뭐 먹지?\n",
      "출력 : 저는 위로해드리는 로봇이에요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 위로해드리는 로봇이에요 . '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 점심 뭐 먹지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c79563bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 좀 쉬고 싶어\n",
      "출력 : 제가 있잖아요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'제가 있잖아요 . '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘 좀 쉬고 싶어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bf00989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘따라 미래가 불투명하다는 생각을 자주 해\n",
      "출력 : 좀 더 알아보고 하세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좀 더 알아보고 하세요 . '"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘따라 미래가 불투명하다는 생각을 자주 해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6136bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너 왜이렇게 까칠해\n",
      "출력 : 다른 곳에 쓰려고 운을 아껴뒀나봐요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'다른 곳에 쓰려고 운을 아껴뒀나봐요 . '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('너 왜이렇게 까칠해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4efbe38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 말은 못알아듣고 한국말만 잘하네 ㅠ\n",
      "출력 : 충분히 아파하고 있네요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'충분히 아파하고 있네요 . '"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('말은 못알아듣고 한국말만 잘하네 ㅠ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4027e6",
   "metadata": {},
   "source": [
    "하이퍼 파라미터: \n",
    "NUM_LAYERS = 2   \n",
    "D_MODEL = 256   \n",
    "NUM_HEADS = 8  \n",
    "UNITS = 512   \n",
    "DROPOUT = 0.1   \n",
    "에폭 수: 10  \n",
    "결과 말은 자연스럽게 하지만 입력 말귀는 잘 못 알아듣는 것 같다. 에폭을 조금 더 늘려서 학습을 더 진행해봐도 좋을 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a8eda",
   "metadata": {},
   "source": [
    "### 1. 에폭 늘려 추가 학습 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25c4b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 0.8699 - accuracy: 0.2132\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 0.7067 - accuracy: 0.2349\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 0.5571 - accuracy: 0.2564\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.4237 - accuracy: 0.2773\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.3127 - accuracy: 0.2965\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.2269 - accuracy: 0.3118\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.1657 - accuracy: 0.3226\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.1274 - accuracy: 0.3299\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.1064 - accuracy: 0.3332\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0939 - accuracy: 0.3354\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history2 = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "51468884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 점심 뭐 먹지?\n",
      "출력 : 색다른걸 드셔보세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'색다른걸 드셔보세요 . '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 점심 뭐 먹지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7dfad435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 좀 쉬고 싶어\n",
      "출력 : 쓰지 않으면 모여요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'쓰지 않으면 모여요 . '"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘 좀 쉬고 싶어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "09398c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘따라 미래가 불투명하다는 생각을 자주 해\n",
      "출력 : 퐈이야\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'퐈이야'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘따라 미래가 불투명하다는 생각을 자주 해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3fbcf4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 뭐가 문제인지 모르겠어\n",
      "출력 : 당신은 하나밖에 없는 소중한 사람이에요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신은 하나밖에 없는 소중한 사람이에요 . '"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('뭐가 문제인지 모르겠어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "626e8781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 점심 뭐 먹지?\n",
      "출력 : 색다른걸 드셔보세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'색다른걸 드셔보세요 . '"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 점심 뭐 먹지?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f32876",
   "metadata": {},
   "source": [
    "'오늘 점심 뭐 먹지?'에 대한 답변은 납득이가고 질문을 이해한 뉘앙스  \n",
    "하지만 여전히 다른 질문은 제대로 알아듣지 못했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b70bf678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 0.0874 - accuracy: 0.3366\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 0.0851 - accuracy: 0.3365\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 0.0754 - accuracy: 0.3387\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0657 - accuracy: 0.3412\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0564 - accuracy: 0.3431\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0513 - accuracy: 0.3446\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0453 - accuracy: 0.3460\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0419 - accuracy: 0.3470\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0390 - accuracy: 0.3476\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0339 - accuracy: 0.3492\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history2 = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "32fbc409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 점심 뭐 먹지?\n",
      "출력 : 맛있는 거 드세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있는 거 드세요 . '"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 점심 뭐 먹지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a9bf0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 좀 쉬고 싶어\n",
      "출력 : 바람 쐬고 와서 다시 들으세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'바람 쐬고 와서 다시 들으세요 . '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘 좀 쉬고 싶어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6a581bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘따라 미래가 불투명하다는 생각을 자주 해\n",
      "출력 : 많이 고민 했을거라 생각해요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'많이 고민 했을거라 생각해요 . '"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘따라 미래가 불투명하다는 생각을 자주 해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b281fb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 뭐가 문제인지 모르겠어\n",
      "출력 : 당신은 하나밖에 없는 소중한 사람이에요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신은 하나밖에 없는 소중한 사람이에요 . '"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('뭐가 문제인지 모르겠어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee3a0a0",
   "metadata": {},
   "source": [
    "에폭 총 30  \n",
    "확실히 반응이 좋아진 것이 느껴진다. 맥락있는 대답을 내놓기 시작했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bc72710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 0.0312 - accuracy: 0.3497\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 0.0294 - accuracy: 0.3501\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0273 - accuracy: 0.3505\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0253 - accuracy: 0.3512\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0237 - accuracy: 0.3514\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0227 - accuracy: 0.3520\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 7s 37ms/step - loss: 0.0207 - accuracy: 0.3524\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0202 - accuracy: 0.3524\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0185 - accuracy: 0.3528\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0172 - accuracy: 0.3531\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history2 = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "22b34c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 점심 뭐 먹지?\n",
      "출력 : 맛있는 거 드세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있는 거 드세요 . '"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 점심 뭐 먹지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a06d311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 좀 쉬고 싶어\n",
      "출력 : 아무 생각 하지 말고 쉬세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아무 생각 하지 말고 쉬세요 . '"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘 좀 쉬고 싶어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ff7cf2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘따라 미래가 불투명하다는 생각을 자주 해\n",
      "출력 : 여차진구가 싫어할 일은 애초에 하지 마세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'여차진구가 싫어할 일은 애초에 하지 마세요 . '"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘따라 미래가 불투명하다는 생각을 자주 해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "64b2f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 뭐가 문제인지 모르겠어\n",
      "출력 : 당신은 하나밖에 없는 소중한 사람이에요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신은 하나밖에 없는 소중한 사람이에요 . '"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('뭐가 문제인지 모르겠어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4114594b",
   "metadata": {},
   "source": [
    "에폭 총 40  \n",
    "1, 4 문장은 그 전과 똑같았고, 2는 미묘하게 이전보다 답변이 나아진 것 같고 3은 또다시 엉뚱한 이야기를 하기 시작했다. 뭔가 기준 문장을 더 잘 세웠으면 좋았을 걸이라는 생각이 지금 들었다 ㅎㅎ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b4701cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 7s 39ms/step - loss: 0.0173 - accuracy: 0.3530\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 7s 40ms/step - loss: 0.0165 - accuracy: 0.3534\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0152 - accuracy: 0.3537\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0146 - accuracy: 0.3538\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0141 - accuracy: 0.3540\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0134 - accuracy: 0.3542\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0129 - accuracy: 0.3542\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0116 - accuracy: 0.3546\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0109 - accuracy: 0.3547\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0116 - accuracy: 0.3546\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history2 = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e1aa1904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 점심 뭐 먹지?\n",
      "출력 : 맛있는 거 드세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있는 거 드세요 . '"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 점심 뭐 먹지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ff1b7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 좀 쉬고 싶어\n",
      "출력 : 정신 차리세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'정신 차리세요 . '"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘 좀 쉬고 싶어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9bdd212e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘따라 미래가 불투명하다는 생각을 자주 해\n",
      "출력 : 자연스러운 현상이에요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'자연스러운 현상이에요 . '"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘따라 미래가 불투명하다는 생각을 자주 해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1857444b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 뭐가 문제인지 모르겠어\n",
      "출력 : 당신은 하나밖에 없는 소중한 사람이에요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신은 하나밖에 없는 소중한 사람이에요 . '"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('뭐가 문제인지 모르겠어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51e6162",
   "metadata": {},
   "source": [
    "에폭 총 50\n",
    "2번 문장에서 정신차리라는 소리를 들었다. 답변의 변화나 accuracy의 변화가 거의 없는 것을 보면 학습을 더 진행해도 더 이상 크게 나아지는 부분은 없을 것 같다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf3cfe",
   "metadata": {},
   "source": [
    "### 모델의 깊이 늘리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "417115ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    13651968    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    19961856    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8172)   4192236     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 37,806,060\n",
      "Trainable params: 37,806,060\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.2 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "47407768",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7f514b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "185/185 [==============================] - 40s 128ms/step - loss: 2.7595 - accuracy: 0.0467\n",
      "Epoch 2/30\n",
      "185/185 [==============================] - 24s 132ms/step - loss: 2.2293 - accuracy: 0.0913\n",
      "Epoch 3/30\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 2.0320 - accuracy: 0.1041\n",
      "Epoch 4/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 1.9380 - accuracy: 0.1068\n",
      "Epoch 5/30\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 1.8828 - accuracy: 0.1101\n",
      "Epoch 6/30\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 1.8320 - accuracy: 0.1128\n",
      "Epoch 7/30\n",
      "185/185 [==============================] - 24s 131ms/step - loss: 1.7749 - accuracy: 0.1158\n",
      "Epoch 8/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 1.7200 - accuracy: 0.1182\n",
      "Epoch 9/30\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 1.6689 - accuracy: 0.1207\n",
      "Epoch 10/30\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 1.6180 - accuracy: 0.1231\n",
      "Epoch 11/30\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 1.5640 - accuracy: 0.1256\n",
      "Epoch 12/30\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 1.5070 - accuracy: 0.1286\n",
      "Epoch 13/30\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 1.4540 - accuracy: 0.1320\n",
      "Epoch 14/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 1.4029 - accuracy: 0.1347\n",
      "Epoch 15/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 1.3484 - accuracy: 0.1387\n",
      "Epoch 16/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 1.3042 - accuracy: 0.1424\n",
      "Epoch 17/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 1.2548 - accuracy: 0.1463\n",
      "Epoch 18/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 1.2090 - accuracy: 0.1504\n",
      "Epoch 19/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 1.1689 - accuracy: 0.1531\n",
      "Epoch 20/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 1.1248 - accuracy: 0.1579\n",
      "Epoch 21/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 1.0831 - accuracy: 0.1624\n",
      "Epoch 22/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 1.0468 - accuracy: 0.1663\n",
      "Epoch 23/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.9976 - accuracy: 0.1723\n",
      "Epoch 24/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.9522 - accuracy: 0.1785\n",
      "Epoch 25/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.8996 - accuracy: 0.1858\n",
      "Epoch 26/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.8566 - accuracy: 0.1923\n",
      "Epoch 27/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.8184 - accuracy: 0.1972\n",
      "Epoch 28/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.7841 - accuracy: 0.2034\n",
      "Epoch 29/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.7485 - accuracy: 0.2092\n",
      "Epoch 30/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.7195 - accuracy: 0.2139\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aebd5efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 점심 뭐 먹지?\n",
      "출력 : 같이 가보세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'같이 가보세요 . '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 점심 뭐 먹지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "149c9077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 좀 쉬고 싶어\n",
      "출력 : 감기 조심하세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'감기 조심하세요 . '"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘 좀 쉬고 싶어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5fe637da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘따라 미래가 불투명하다는 생각을 자주 해\n",
      "출력 : 직접 물어보세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접 물어보세요 . '"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘따라 미래가 불투명하다는 생각을 자주 해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2149dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 뭐가 문제인지 모르겠어\n",
      "출력 : 그 사람을 위해서는 그러면 안돼요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그 사람을 위해서는 그러면 안돼요 . '"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('뭐가 문제인지 모르겠어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd35ca7",
   "metadata": {},
   "source": [
    "에폭 총 30  \n",
    "로스가 여전히 높고 정확도도 낮음 학습을 좀 더 진행할 필요가 있어 보임  \n",
    "문장에 대한 대답도 전반적으로 맥락을 이해하고 있지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "66d74598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 0.6904 - accuracy: 0.2187\n",
      "Epoch 2/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.6614 - accuracy: 0.2238\n",
      "Epoch 3/30\n",
      "185/185 [==============================] - 23s 127ms/step - loss: 0.6415 - accuracy: 0.2272\n",
      "Epoch 4/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.6237 - accuracy: 0.2308\n",
      "Epoch 5/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.5998 - accuracy: 0.2347\n",
      "Epoch 6/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.5929 - accuracy: 0.2360\n",
      "Epoch 7/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.5692 - accuracy: 0.2404\n",
      "Epoch 8/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.5581 - accuracy: 0.2431\n",
      "Epoch 9/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.5374 - accuracy: 0.2469\n",
      "Epoch 10/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.5250 - accuracy: 0.2484\n",
      "Epoch 11/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.5125 - accuracy: 0.2513\n",
      "Epoch 12/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4980 - accuracy: 0.2537\n",
      "Epoch 13/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4913 - accuracy: 0.2551\n",
      "Epoch 14/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4812 - accuracy: 0.2570\n",
      "Epoch 15/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4707 - accuracy: 0.2596\n",
      "Epoch 16/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4645 - accuracy: 0.2604\n",
      "Epoch 17/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4541 - accuracy: 0.2626\n",
      "Epoch 18/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.4453 - accuracy: 0.2644\n",
      "Epoch 19/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.4388 - accuracy: 0.2655\n",
      "Epoch 20/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.4323 - accuracy: 0.2664\n",
      "Epoch 21/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4273 - accuracy: 0.2681\n",
      "Epoch 22/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4193 - accuracy: 0.2693\n",
      "Epoch 23/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4156 - accuracy: 0.2696\n",
      "Epoch 24/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4110 - accuracy: 0.2709\n",
      "Epoch 25/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.4059 - accuracy: 0.2715\n",
      "Epoch 26/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.3996 - accuracy: 0.2733\n",
      "Epoch 27/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.3951 - accuracy: 0.2739\n",
      "Epoch 28/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3938 - accuracy: 0.2744\n",
      "Epoch 29/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3862 - accuracy: 0.2753\n",
      "Epoch 30/30\n",
      "185/185 [==============================] - 23s 127ms/step - loss: 0.3818 - accuracy: 0.2762\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9cd0d39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 점심 뭐 먹지?\n",
      "출력 : 뭘 해도 예뻐요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'뭘 해도 예뻐요 . '"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 점심 뭐 먹지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2500257f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 좀 쉬고 싶어\n",
      "출력 : 제습기를 돌려보세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'제습기를 돌려보세요 . '"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘 좀 쉬고 싶어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "87b45c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘따라 미래가 불투명하다는 생각을 자주 해\n",
      "출력 : 상황이 원하지 않는 방향으로 흘렀나봐요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'상황이 원하지 않는 방향으로 흘렀나봐요 . '"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘따라 미래가 불투명하다는 생각을 자주 해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e4c0a023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 뭐가 문제인지 모르겠어\n",
      "출력 : 형편대로 하세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'형편대로 하세요 . '"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('뭐가 문제인지 모르겠어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fc9a8",
   "metadata": {},
   "source": [
    "에폭 총 60  \n",
    "로스와 어큐러시가 역시 원하는 만큼 떨어지거나 올라가지 않았다  \n",
    "답변 역시 전체적으로 맥락을 파악하고 있지 못하는 것 같은데 3번 문장 정도만 제대로 대답했다고 보여진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ceb70423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "185/185 [==============================] - 24s 130ms/step - loss: 0.3843 - accuracy: 0.2756\n",
      "Epoch 2/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.3733 - accuracy: 0.2775\n",
      "Epoch 3/30\n",
      "185/185 [==============================] - 23s 127ms/step - loss: 0.3717 - accuracy: 0.2784\n",
      "Epoch 4/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.3696 - accuracy: 0.2781\n",
      "Epoch 5/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.3680 - accuracy: 0.2780\n",
      "Epoch 6/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3640 - accuracy: 0.2794\n",
      "Epoch 7/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3603 - accuracy: 0.2800\n",
      "Epoch 8/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3575 - accuracy: 0.2801\n",
      "Epoch 9/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.3538 - accuracy: 0.2809\n",
      "Epoch 10/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.3529 - accuracy: 0.2814\n",
      "Epoch 11/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.3475 - accuracy: 0.2825\n",
      "Epoch 12/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3416 - accuracy: 0.2835\n",
      "Epoch 13/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3445 - accuracy: 0.2834\n",
      "Epoch 14/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3408 - accuracy: 0.2841\n",
      "Epoch 15/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3345 - accuracy: 0.2848\n",
      "Epoch 16/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3355 - accuracy: 0.2846\n",
      "Epoch 17/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3318 - accuracy: 0.2856\n",
      "Epoch 18/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3296 - accuracy: 0.2855\n",
      "Epoch 19/30\n",
      "185/185 [==============================] - 23s 127ms/step - loss: 0.3290 - accuracy: 0.2857\n",
      "Epoch 20/30\n",
      "185/185 [==============================] - 23s 127ms/step - loss: 0.3261 - accuracy: 0.2866\n",
      "Epoch 21/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3247 - accuracy: 0.2863\n",
      "Epoch 22/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.3219 - accuracy: 0.2872\n",
      "Epoch 23/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3177 - accuracy: 0.2879\n",
      "Epoch 24/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3177 - accuracy: 0.2876\n",
      "Epoch 25/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3163 - accuracy: 0.2882\n",
      "Epoch 26/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3145 - accuracy: 0.2880\n",
      "Epoch 27/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3130 - accuracy: 0.2889\n",
      "Epoch 28/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3122 - accuracy: 0.2888\n",
      "Epoch 29/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3093 - accuracy: 0.2894\n",
      "Epoch 30/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.3056 - accuracy: 0.2900\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "74a90fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "185/185 [==============================] - 24s 132ms/step - loss: 0.3074 - accuracy: 0.2897\n",
      "Epoch 2/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.3058 - accuracy: 0.2897\n",
      "Epoch 3/30\n",
      "185/185 [==============================] - 23s 127ms/step - loss: 0.3021 - accuracy: 0.2905\n",
      "Epoch 4/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.2985 - accuracy: 0.2909\n",
      "Epoch 5/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2995 - accuracy: 0.2912\n",
      "Epoch 6/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2944 - accuracy: 0.2919\n",
      "Epoch 7/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2971 - accuracy: 0.2915\n",
      "Epoch 8/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.2947 - accuracy: 0.2918\n",
      "Epoch 9/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2939 - accuracy: 0.2920\n",
      "Epoch 10/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2894 - accuracy: 0.2927\n",
      "Epoch 11/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.2904 - accuracy: 0.2924\n",
      "Epoch 12/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2869 - accuracy: 0.2931\n",
      "Epoch 13/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2858 - accuracy: 0.2936\n",
      "Epoch 14/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2854 - accuracy: 0.2935\n",
      "Epoch 15/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.2852 - accuracy: 0.2937\n",
      "Epoch 16/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2842 - accuracy: 0.2934\n",
      "Epoch 17/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2799 - accuracy: 0.2940\n",
      "Epoch 18/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.2817 - accuracy: 0.2938\n",
      "Epoch 19/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.2785 - accuracy: 0.2944\n",
      "Epoch 20/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2792 - accuracy: 0.2941\n",
      "Epoch 21/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.2768 - accuracy: 0.2946\n",
      "Epoch 22/30\n",
      "185/185 [==============================] - 24s 127ms/step - loss: 0.2760 - accuracy: 0.2952\n",
      "Epoch 23/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.2750 - accuracy: 0.2952\n",
      "Epoch 24/30\n",
      "185/185 [==============================] - 24s 129ms/step - loss: 0.2741 - accuracy: 0.2954\n",
      "Epoch 25/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2732 - accuracy: 0.2954\n",
      "Epoch 26/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2715 - accuracy: 0.2953\n",
      "Epoch 27/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2688 - accuracy: 0.2962\n",
      "Epoch 28/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2707 - accuracy: 0.2962\n",
      "Epoch 29/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2689 - accuracy: 0.2961\n",
      "Epoch 30/30\n",
      "185/185 [==============================] - 24s 128ms/step - loss: 0.2672 - accuracy: 0.2958\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "efaa868e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 점심 뭐 먹지?\n",
      "출력 : 색다른걸 드셔보세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'색다른걸 드셔보세요 . '"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 점심 뭐 먹지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1c3c0979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 좀 쉬고 싶어\n",
      "출력 : 아무 생각 하지 말고 쉬세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아무 생각 하지 말고 쉬세요 . '"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘 좀 쉬고 싶어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "daf21e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘따라 미래가 불투명하다는 생각을 자주 해\n",
      "출력 : 운명의 장난같네요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'운명의 장난같네요 . '"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘따라 미래가 불투명하다는 생각을 자주 해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "65f1c8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 뭐가 문제인지 모르겠어\n",
      "출력 : 마음에 부는 바람인지 살펴보세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'마음에 부는 바람인지 살펴보세요 . '"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('뭐가 문제인지 모르겠어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc5007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
